{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Write a python program to display all the header tags from wikipedia.org.\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#finding all the header tags and assigning them to a variable\n",
    "header_tags=soup.find_all('span',class_='mw-headline')\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "#calling the variable To display the header tags\n",
    "header_tags\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page1=requests.get(\"https://www.imdb.com/chart/top\")\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page1\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup1=BeautifulSoup(page1.content,'html.parser')\n",
    "soup1\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "#creating empty lists for storing the required data\n",
    "Movie = []\n",
    "Year = []\n",
    "Rating = []\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "#Under Title column there is title & year, for only getting the title tag \"a\" is used along with 'titlecolum' class\n",
    "#Movie year is under the same title column parent tag, with a seperate class \"secondaryInfo\"\n",
    "#\n",
    "movie_name = soup1.select(\"td.titleColumn a\")\n",
    "for i in movie_name:\n",
    "    Movie.append(i.get_text())\n",
    "movie_year = soup1.find_all('span',class_='secondaryInfo')\n",
    "for i in movie_year:\n",
    "    Year.append(i.get_text().replace('\\n','').replace('(','').replace(')',''))\n",
    "movie_rating = soup1.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "for i in movie_rating:\n",
    "    Rating.append(i.get_text().replace('\\n',''))\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "Top100 = pd.DataFrame({})\n",
    "Top100['Movie'] = Movie[0:100]\n",
    "Top100['Year'] = Year[0:100]\n",
    "Top100['Rating'] = Rating[0:100]\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "Top100\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "# \n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page2=requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page2\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup2=BeautifulSoup(page2.content,'html.parser')\n",
    "soup2\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "#creating empty lists for storing the required data\n",
    "India_Movie = []\n",
    "India_Year = []\n",
    "India_Rating = []\n",
    "\n",
    "\n",
    "# In[88]:\n",
    "\n",
    "\n",
    "#Under Title column there is title & year, for only getting the title tag \"a\" is used along with 'titlecolum' class\n",
    "#Movie year is under the same title column parent tag, with a seperate class \"secondaryInfo\"\n",
    "#\n",
    "movie_name = soup2.select(\"td.titleColumn a\")\n",
    "for i in movie_name:\n",
    "    India_Movie.append(i.get_text())\n",
    "movie_year = soup2.find_all('span',class_='secondaryInfo')\n",
    "for i in movie_year:\n",
    "    India_Year.append(i.get_text().replace('\\n','').replace('(','').replace(')',''))\n",
    "movie_rating = soup2.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "for i in movie_rating:\n",
    "    India_Rating.append(i.get_text().replace('\\n',''))\n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "\n",
    "India_Top100 = pd.DataFrame({})\n",
    "India_Top100['Movie'] = India_Movie[0:100]\n",
    "India_Top100['Year'] = India_Year[0:100]\n",
    "India_Top100['Rating'] = India_Rating[0:100]\n",
    "\n",
    "\n",
    "# In[90]:\n",
    "\n",
    "\n",
    "India_Top100\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page3=requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page3\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup3=BeautifulSoup(page3.content,'html.parser')\n",
    "soup3\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "#creating empty lists for storing the required data\n",
    "President_Name=[]\n",
    "Office_Term=[]\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "for i in soup3.find_all('h3'):\n",
    "    President_Name.append(i.get_text(strip=True).split('(')[0])\n",
    "for i in soup3.find_all('p'):\n",
    "    Office_Term.append(i.get_text(strip=True))\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "President_Name\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "Office_Term\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "Office_Term.pop(1)\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "#removed individual items other than office term by repeatedly executing the pop operation\n",
    "\n",
    "Office_Term.pop(14)\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "Former_pre_List=pd.DataFrame({})\n",
    "Former_pre_List['Name']=President_Name\n",
    "Former_pre_List['Term']=Office_Term\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "Former_pre_List\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# #a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "# #b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "# #c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "#Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page4=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page4\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup4=BeautifulSoup(page4.content,'html.parser')\n",
    "soup4\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "#creating empty team list and finding all team names and saving in to the team\n",
    "Team=[]\n",
    "for i in soup4.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    Team.append(i.text)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "#creating empty matches and points list and saving the points & matches in the lists\n",
    "#As the matches and Points are under the same class and tags both are coming under single list, so seperating them\n",
    "#Also the top No.1 team has different tag and class with banner, so we are scraping it seperately and appending it to the remaing list\n",
    "\n",
    "Matches=[]\n",
    "Points=[]\n",
    "ODI_MMatches=soup4.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "for i in range(0,len(ODI_MMatches),2):\n",
    "    Matches.append(ODI_MMatches[i].get_text().replace(',',''))\n",
    "    Points.append(ODI_MMatches[i+1].get_text().replace(',',''))\n",
    "match_1 = soup4.find(\"td\",class_=\"rankings-block__banner--matches\").get_text()\n",
    "Matches.insert(0,match_1)\n",
    "points_1 = soup4.find('td',class_=\"rankings-block__banner--points\").get_text().replace(',','')\n",
    "Points.insert(0,points_1)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "# ccreating empty rating list and saving the ratings to list like above\n",
    "Rating=[]\n",
    "rating_all = soup4.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "for i in rating_all:\n",
    "    Rating.append(i.get_text().replace('\\n',''))\n",
    "Rating_1 = soup4.find('td', class_=\"rankings-block__banner--rating u-text-right\").get_text().replace('\\n','').strip()\n",
    "Rating.insert(0,Rating_1)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "#assigning the lists to a pandas data frame and saving the first 10 in the lists to the DF\n",
    "ICC_top_10_MTeams = pd.DataFrame({})\n",
    "ICC_top_10_MTeams['Team'] = Team[0:10]\n",
    "ICC_top_10_MTeams['Matches'] = Matches[0:10]\n",
    "ICC_top_10_MTeams['Points'] = Points[0:10]\n",
    "ICC_top_10_MTeams['Rating'] = Rating[0:10]\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "ICC_top_10_MTeams\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page5=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page5\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup5=BeautifulSoup(page5.text,'html.parser')\n",
    "soup5\n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "#creating empty lists for storing names and details\n",
    "Name=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "#top 1 player has different class & tags as he is highlighted in a banner\n",
    "#remaining players to be scraped seperately and both to be combined\n",
    "\n",
    "Player1 = soup5.find(\"div\",class_=\"rankings-block__banner--name-large\").get_text()\n",
    "\n",
    "Player_all = soup5.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "\n",
    "for i in Player_all:\n",
    "    Name.append(i.get_text().replace('\\n',''))\n",
    "Name.insert(0,Player1)\n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "\n",
    "#scraping the players team like above\n",
    "Player1_Team=soup5.find('div',class_=\"rankings-block__banner--nationality\").get_text().replace('\\n','')\n",
    "Playerall_Teams=soup5.find_all('span',class_=\"table-body__logo-text\")\n",
    "for i in Playerall_Teams:\n",
    "    Team.append(i.get_text())\n",
    "Team.insert(0,Player1_Team)\n",
    "\n",
    "\n",
    "# In[92]:\n",
    "\n",
    "\n",
    "#scraping the players ratings like above\n",
    "Player1_Rating=soup5.find('div',class_='rankings-block__banner--rating').get_text()\n",
    "Playerall_Rating=soup5.find_all('td',class_='table-body__cell rating')\n",
    "for i in Playerall_Rating:\n",
    "    Rating.append(i.get_text())\n",
    "Rating.insert(0,Player1_Rating)\n",
    "\n",
    "\n",
    "# In[93]:\n",
    "\n",
    "\n",
    "#now building the pandas data frame with the data extracted\n",
    "ODI_MenBat_10=pd.DataFrame({})\n",
    "ODI_MenBat_10['Player']=Name[0:10]\n",
    "ODI_MenBat_10['Team']=Team[0:10]\n",
    "ODI_MenBat_10['Rating']=Rating[0:10]\n",
    "\n",
    "\n",
    "# In[94]:\n",
    "\n",
    "\n",
    "ODI_MenBat_10\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Top 10 ODI bowlers along with the records of their team and rating.\n",
    "# \n",
    "\n",
    "# In[95]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# In[96]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page6=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "page6\n",
    "\n",
    "\n",
    "# In[99]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup6=BeautifulSoup(page6.content,\"html.parser\")\n",
    "soup6\n",
    "\n",
    "\n",
    "# In[116]:\n",
    "\n",
    "\n",
    "#creating empty lists for storing names and details\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n",
    "\n",
    "#top 1 player has different class & tags as he is highlighted in a banner\n",
    "#remaining players to be scraped seperately and both to be combined\n",
    "Player1=soup6.find('div',\"rankings-block__banner--name-large\").get_text()\n",
    "PlayerAll=soup6.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in PlayerAll:\n",
    "    Player.append(i.get_text().replace('\\n',''))\n",
    "Player.insert(0,Player1)\n",
    "\n",
    "\n",
    "# In[118]:\n",
    "\n",
    "\n",
    "#scraping the players team like above\n",
    "Player1_Team=soup6.find('div',class_='rankings-block__banner--nationality').get_text().replace('\\n','')\n",
    "PlayerAll_Team=soup6.find_all('span',class_='table-body__logo-text')\n",
    "for i in PlayerAll_Team:\n",
    "    Team.append(i.get_text())\n",
    "Team.insert(0,Player1_Team)\n",
    "\n",
    "\n",
    "# In[119]:\n",
    "\n",
    "\n",
    "#scraping the players Ratings like above\n",
    "Player1_Rating=soup6.find('div',class_='rankings-block__banner--rating').get_text()\n",
    "PlayerAll_Rating=soup6.find_all('td',class_='table-body__cell rating')\n",
    "for i in PlayerAll_Rating:\n",
    "    Rating.append(i.get_text())\n",
    "Rating.insert(0,Player1_Rating)\n",
    "\n",
    "\n",
    "# In[120]:\n",
    "\n",
    "\n",
    "#now building the pandas data frame with the data extracted & Displaying the DATA FRAME\n",
    "ODI_MenBow_10=pd.DataFrame({})\n",
    "ODI_MenBow_10['Player']=Player[0:10]\n",
    "ODI_MenBow_10['Team']=Team[0:10]\n",
    "ODI_MenBow_10['Rating']=Rating[0:10]\n",
    "ODI_MenBow_10\n",
    "\n",
    "\n",
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "# In[121]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# In[122]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "page7=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "page7\n",
    "\n",
    "\n",
    "# In[123]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup7=BeautifulSoup(page7.content,\"html.parser\")\n",
    "soup7\n",
    "\n",
    "\n",
    "# In[125]:\n",
    "\n",
    "\n",
    "#creating empty team list and finding all team names and saving in to the team (As all team names coming under same tag&class)\n",
    "Team=[]\n",
    "for i in soup7.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    Team.append(i.text)\n",
    "\n",
    "\n",
    "# In[128]:\n",
    "\n",
    "\n",
    "#creating empty matches and points list and saving the points & matches in the lists\n",
    "#As the matches and Points are under the same class and tags both are coming under single list, so seperating them\n",
    "#Also the top No.1 team has different tag and class with banner, so we are scraping it seperately and appending it to the remaing list\n",
    "\n",
    "Matches=[]\n",
    "Points=[]\n",
    "ODI_WMatches=soup7.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "for i in range(0,len(ODI_WMatches),2):\n",
    "    Matches.append(ODI_WMatches[i].get_text().replace(',',''))\n",
    "    Points.append(ODI_WMatches[i+1].get_text().replace(',',''))\n",
    "match_1 = soup7.find(\"td\",class_=\"rankings-block__banner--matches\").get_text()\n",
    "Matches.insert(0,match_1)\n",
    "points_1 = soup7.find('td',class_=\"rankings-block__banner--points\").get_text().replace(',','')\n",
    "Points.insert(0,points_1)\n",
    "\n",
    "\n",
    "# In[130]:\n",
    "\n",
    "\n",
    "# ccreating empty rating list and saving the ratings to list like above\n",
    "Rating=[]\n",
    "rating_all = soup7.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "for i in rating_all:\n",
    "    Rating.append(i.get_text().replace('\\n',''))\n",
    "Rating_1 = soup7.find('td', class_=\"rankings-block__banner--rating u-text-right\").get_text().replace('\\n','').strip()\n",
    "Rating.insert(0,Rating_1)\n",
    "\n",
    "\n",
    "# In[131]:\n",
    "\n",
    "\n",
    "#assigning the lists to a pandas data frame and saving the first 10 in the lists to the DF & Accessing the DF\n",
    "ICC_top_10_WTeams = pd.DataFrame({})\n",
    "ICC_top_10_WTeams['Team'] = Team[0:10]\n",
    "ICC_top_10_WTeams['Matches'] = Matches[0:10]\n",
    "ICC_top_10_WTeams['Points'] = Points[0:10]\n",
    "ICC_top_10_WTeams['Rating'] = Rating[0:10]\n",
    "ICC_top_10_WTeams\n",
    "\n",
    "\n",
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "# In[132]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page8=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "page8\n",
    "\n",
    "\n",
    "# In[135]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup8=BeautifulSoup(page8.text,'html.parser')\n",
    "soup8\n",
    "\n",
    "\n",
    "# In[138]:\n",
    "\n",
    "\n",
    "#creating empty lists for storing names and details\n",
    "Name=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "# In[139]:\n",
    "\n",
    "\n",
    "#top 1 player has different class & tags as he is highlighted in a banner\n",
    "#remaining players to be scraped seperately and both to be combined\n",
    "\n",
    "Player1 = soup8.find(\"div\",class_=\"rankings-block__banner--name-large\").get_text()\n",
    "\n",
    "Player_all = soup8.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "\n",
    "for i in Player_all:\n",
    "    Name.append(i.get_text().replace('\\n',''))\n",
    "Name.insert(0,Player1)\n",
    "\n",
    "\n",
    "# In[140]:\n",
    "\n",
    "\n",
    "#scraping the players team like above\n",
    "Player1_Team=soup8.find('div',class_=\"rankings-block__banner--nationality\").get_text().replace('\\n','')\n",
    "Playerall_Teams=soup8.find_all('span',class_=\"table-body__logo-text\")\n",
    "for i in Playerall_Teams:\n",
    "    Team.append(i.get_text())\n",
    "Team.insert(0,Player1_Team)\n",
    "\n",
    "\n",
    "# In[141]:\n",
    "\n",
    "\n",
    "#scraping the players ratings like above\n",
    "Player1_Rating=soup8.find('div',class_='rankings-block__banner--rating').get_text()\n",
    "Playerall_Rating=soup8.find_all('td',class_='table-body__cell rating')\n",
    "for i in Playerall_Rating:\n",
    "    Rating.append(i.get_text())\n",
    "Rating.insert(0,Player1_Rating)\n",
    "\n",
    "\n",
    "# In[142]:\n",
    "\n",
    "\n",
    "#now building the pandas data frame with the data extracted &accessing the DF\n",
    "ODI_WMenBat_10=pd.DataFrame({})\n",
    "ODI_WMenBat_10['Player']=Name[0:10]\n",
    "ODI_WMenBat_10['Team']=Team[0:10]\n",
    "ODI_WMenBat_10['Rating']=Rating[0:10]\n",
    "ODI_WMenBat_10\n",
    "\n",
    "\n",
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "# In[143]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# In[144]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page9=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "page9\n",
    "\n",
    "\n",
    "# In[145]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup9=BeautifulSoup(page9.text,'html.parser')\n",
    "soup9\n",
    "\n",
    "\n",
    "# In[146]:\n",
    "\n",
    "\n",
    "#creating empty lists for storing names and details\n",
    "Name=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "# In[147]:\n",
    "\n",
    "\n",
    "#top 1 player has different class & tags as he is highlighted in a banner\n",
    "#remaining players to be scraped seperately and both to be combined\n",
    "\n",
    "Player1 = soup9.find(\"div\",class_=\"rankings-block__banner--name-large\").get_text()\n",
    "\n",
    "Player_all = soup9.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "\n",
    "for i in Player_all:\n",
    "    Name.append(i.get_text().replace('\\n',''))\n",
    "Name.insert(0,Player1)\n",
    "\n",
    "\n",
    "# In[149]:\n",
    "\n",
    "\n",
    "#scraping the players team like above\n",
    "Player1_Team=soup9.find('div',class_=\"rankings-block__banner--nationality\").get_text().replace('\\n','')\n",
    "Playerall_Teams=soup9.find_all('span',class_=\"table-body__logo-text\")\n",
    "for i in Playerall_Teams:\n",
    "    Team.append(i.get_text())\n",
    "Team.insert(0,Player1_Team)\n",
    "\n",
    "\n",
    "# In[150]:\n",
    "\n",
    "\n",
    "#scraping the players ratings like above\n",
    "Player1_Rating=soup9.find('div',class_='rankings-block__banner--rating').get_text()\n",
    "Playerall_Rating=soup9.find_all('td',class_='table-body__cell rating')\n",
    "for i in Playerall_Rating:\n",
    "    Rating.append(i.get_text())\n",
    "Rating.insert(0,Player1_Rating)\n",
    "\n",
    "\n",
    "# In[151]:\n",
    "\n",
    "\n",
    "#now building the pandas data frame with the data extracted &accessing the DF\n",
    "ODI_WMenAR_10=pd.DataFrame({})\n",
    "ODI_WMenAR_10['Player']=Name[0:10]\n",
    "ODI_WMenAR_10['Team']=Team[0:10]\n",
    "ODI_WMenAR_10['Rating']=Rating[0:10]\n",
    "ODI_WMenAR_10\n",
    "\n",
    "\n",
    "# As men & Women ODI batting & All rounder , Bowling scraping is similar we can make a user defined function\n",
    "# We can also get test, T20 rankings for individuals \n",
    "# \n",
    "# This function can be run after importing the required libraries\n",
    "# \n",
    "# Team ranking has different tags, so that can be done in other user defined function\n",
    "\n",
    "# In[167]:\n",
    "\n",
    "\n",
    "def ICC_Top10(url):\n",
    "    Name=[]\n",
    "    Team=[]\n",
    "    Rating=[]\n",
    "\n",
    "    Page = requests.get(url)\n",
    "    soup = BeautifulSoup(Page.content, 'html.parser')\n",
    "    Player1 = soup.find(\"div\",class_=\"rankings-block__banner--name-large\").get_text()\n",
    "    Player_All = soup.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "    for i in Player_All:\n",
    "        Name.append(i.get_text().replace('\\n',''))\n",
    "    Name.insert(0,Player1)\n",
    "    \n",
    "    #Scraping the team\n",
    "    Player1_Team = soup.find('div',class_='rankings-block__banner--nationality').get_text().replace('\\n','')\n",
    "    PlayerAll_Team = soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in PlayerAll_Team:\n",
    "        Team.append(i.get_text())\n",
    "    Team.insert(0,Player1_Team) \n",
    "    #Rating scraping\n",
    "    Player1_Rating = soup.find('div',class_=\"rankings-block__banner--rating\").get_text().replace('\\n','')\n",
    "    Player_Allrating = soup.find_all('td',class_=\"table-body__cell rating\")\n",
    "    for i in Player_Allrating:\n",
    "        Rating.append(i.get_text().replace('\\n',''))\n",
    "    Rating.insert(0,Player1_Rating)\n",
    "    \n",
    "    ICC_Top10 = pd.DataFrame({})\n",
    "    ICC_Top10['Name'] = Name[0:10]\n",
    "    ICC_Top10['Team'] = Team[0:10]\n",
    "    ICC_Top10['Rating'] = Rating[0:10]\n",
    "    print(ICC_Top10)\n",
    "\n",
    "\n",
    "# In[168]:\n",
    "\n",
    "\n",
    "ICC_Top10('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "\n",
    "# In[169]:\n",
    "\n",
    "\n",
    "ICC_Top10('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "\n",
    "\n",
    "# In[170]:\n",
    "\n",
    "\n",
    "ICC_Top10('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "\n",
    "\n",
    "# In[171]:\n",
    "\n",
    "\n",
    "ICC_Top10('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "# i) Headline\n",
    "# ii) Time\n",
    "# iii) News Link\n",
    "\n",
    "# In[173]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# In[174]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page=requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "page\n",
    "\n",
    "\n",
    "# In[175]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "soup\n",
    "\n",
    "\n",
    "# In[180]:\n",
    "\n",
    "\n",
    "Head_line=[]\n",
    "for i in soup.find_all('div',class_='RiverHeadline-headline RiverHeadline-hasThumbnail'):\n",
    "   Head_line.append(i.text)\n",
    "Head_line\n",
    "\n",
    "\n",
    "# In[181]:\n",
    "\n",
    "\n",
    "time=[]\n",
    "for i in soup.find_all('time'):\n",
    "   time.append(i.text)\n",
    "time\n",
    "\n",
    "\n",
    "# In[183]:\n",
    "\n",
    "\n",
    "page1 = requests.get(\"https://www.cnbc.com/world/?region=world\") \n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "# Retrieve all of the anchor tags\n",
    "# Returns a list of all the links\n",
    "tags=soup1('a')\n",
    "#Prints all the links in the list tags\n",
    "for tag in tags:\n",
    "    # Get the data from href key\n",
    "    print(tag.get('href', None), end = \"\\n\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "# Scrape below mentioned details :\n",
    "# i) Paper Title\n",
    "# ii) Authors\n",
    "# iii) Published Date\n",
    "# iv) Paper URL\n",
    "\n",
    "# In[187]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[188]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page=requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "page\n",
    "\n",
    "\n",
    "# In[189]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "soup\n",
    "\n",
    "\n",
    "# In[237]:\n",
    "\n",
    "\n",
    "#creating empty lists for saving the titles and other details\n",
    "\n",
    "Paper_Title=[]\n",
    "Authors=[]\n",
    "Pub_Date=[]\n",
    "Paper_URL=[]\n",
    "\n",
    "#for extracting the paper titles\n",
    "Papers=soup.find_all('h2',class_='sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg')\n",
    "for i in Papers:\n",
    "    Paper_Title.append(i.get_text())\n",
    "    \n",
    "#for extracting the Author names\n",
    "author=soup.find_all('span',class_='sc-1w3fpd7-0 dnCnAO')\n",
    "for i in author:\n",
    "    Authors.append(i.get_text())\n",
    "    \n",
    "# for extracting the published date\n",
    "PubDate=soup.find_all('span',class_='sc-1thf9ly-2 dvggWt')\n",
    "for i in PubDate:\n",
    "    Pub_Date.append(i.get_text())\n",
    "\n",
    "#for extracting the paper URL\n",
    "soup2=soup.find('div',class_='sc-orwwe2-3 jOMrrY').find_all('a')\n",
    "for i in soup2:\n",
    "    Paper_URL.append(i.get('href', None))\n",
    "\n",
    "\n",
    "# In[243]:\n",
    "\n",
    "\n",
    "Most_Downloaded=pd.DataFrame({})\n",
    "Most_Downloaded['Title']=Paper_Title\n",
    "Most_Downloaded['Author']=Authors\n",
    "Most_Downloaded['Publish Date']=Pub_Date\n",
    "Most_Downloaded['URL']=Paper_URL\n",
    "Most_Downloaded\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "# i) Restaurant name\n",
    "# ii) Cuisine\n",
    "# iii) Location\n",
    "# iv) Ratings\n",
    "# v) Image URL\n",
    "\n",
    "# In[246]:\n",
    "\n",
    "\n",
    "#importing the required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[247]:\n",
    "\n",
    "\n",
    "#sending request to get the html code of the webpage\n",
    "#diplaying whether the page url is scrapable/accessible\n",
    "page=requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "page\n",
    "\n",
    "\n",
    "# In[248]:\n",
    "\n",
    "\n",
    "#getting page html content\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "soup\n",
    "\n",
    "\n",
    "# In[273]:\n",
    "\n",
    "\n",
    "#creating empty lists for saving the names and other details\n",
    "\n",
    "Rest_Name=[]\n",
    "Cuisine=[]\n",
    "Location=[]\n",
    "Rating=[]\n",
    "Image_URL=[]\n",
    "\n",
    "#to get the restaurant names\n",
    "Name=soup.find_all('a',class_='restnt-name ellipsis')\n",
    "for i in Name:\n",
    "    Rest_Name.append(i.get_text())\n",
    "    \n",
    "#to get the cuisine\n",
    "cui=soup.find_all('span',class_='double-line-ellipsis')\n",
    "for i in cui:\n",
    "    Cuisine.append(i.text.split('|')[1])\n",
    "\n",
    "#to get the Location\n",
    "Loc=soup.find_all('div',class_='restnt-loc ellipsis')\n",
    "for i in Loc:\n",
    "    Location.append(i.get_text())\n",
    "    \n",
    "#to get the Rating\n",
    "Rate=soup.find_all('div',class_='restnt-rating rating-4')\n",
    "for i in Rate:\n",
    "    Rating.append(i.get_text())\n",
    "    \n",
    "#to get Image_url\n",
    "imgurl=soup.find_all('img',class_='no-img')\n",
    "for i in imgurl:\n",
    "    Image_URL.append(i.get('data-src'))\n",
    "    \n",
    "\n",
    "\n",
    "# In[274]:\n",
    "\n",
    "\n",
    "Rest_Data=pd.DataFrame({})\n",
    "Rest_Data['Title']=Rest_Name\n",
    "Rest_Data['Cuisine']=Cuisine\n",
    "Rest_Data['LOcation']=Location\n",
    "Rest_Data['Rating']=Rating\n",
    "Rest_Data['ImageURL']=Image_URL\n",
    "Rest_Data\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "# https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "# i) Rank\n",
    "# ii) Publication\n",
    "# iii) h5-index\n",
    "# iv) h5-median\n",
    "\n",
    "# In[275]:\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[276]:\n",
    "\n",
    "\n",
    "page=requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "page\n",
    "\n",
    "\n",
    "# In[277]:\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content,'html.parser')\n",
    "soup\n",
    "\n",
    "\n",
    "# In[299]:\n",
    "\n",
    "\n",
    "\n",
    "#creating empty lists for saving the names and other details\n",
    "Rank=[]\n",
    "Publication=[]\n",
    "H5_Index=[]\n",
    "H5_Median=[]\n",
    "\n",
    "#to get the rank of publication\n",
    "Ranks=soup.find_all('td',class_='gsc_mvt_p')\n",
    "for i in Ranks:\n",
    "    Rank.append(i.get_text())\n",
    "    \n",
    "#to get the publication names    \n",
    "Publ=soup.find_all('td',class_='gsc_mvt_t')\n",
    "for i in Publ:\n",
    "    Publication.append(i.get_text())\n",
    "    \n",
    "    \n",
    "#to get the h5-index\n",
    "H5_ind=soup.find_all('a',class_='gs_ibl gsc_mp_anchor')\n",
    "for i in H5_ind:\n",
    "    H5_Index.append(i.get_text())\n",
    "    \n",
    "\n",
    "#to get the h5-median\n",
    "H5_med=soup.find_all('span',class_='gs_ibl gsc_mp_anchor')\n",
    "for i in H5_med:\n",
    "    H5_Median.append(i.get_text().split(',')[0])\n",
    "    \n",
    "\n",
    "\n",
    "# In[300]:\n",
    "\n",
    "\n",
    "#to create a pandas data frame and saving the lists to DF and accessing it\n",
    "\n",
    "Top_Publications=pd.DataFrame({})\n",
    "Top_Publications['Rank'] = Rank\n",
    "Top_Publications['Publication'] = Publication\n",
    "Top_Publications['h5-index'] = H5_Index\n",
    "Top_Publications['h5-median'] = H5_Median\n",
    "Top_Publications\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "---------------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
